

# 语音识别小组—HyperLips模型

## 1、功能实现

本项目通过重构HyperLips的项目代码，在talkingface-toolkit的框架下实现了HyperLipsBase和HyperLipsHR两个模型的训练和评估。

### HyperLips原理简介

![image-20240127171035279](https://s2.loli.net/2024/01/27/Y8bBmLErZKyNQDn.png)

Hyperlips旨在通过声音同步来提高面部视频的真实性和高保真度。其核心原理是一个两阶段的框架，如图所示：首先，使用基于超网络的方法来控制嘴唇的运动，然后通过高分辨率解码器来渲染高保真的面部图像。

在第一阶段，Hyperlips通过FaceEncoder从视频源提取面部的视觉信息，将其编码成潜码。HyperConv的权重参数由HyperNet根据音频特征更新，用于修改潜码以同步嘴唇的运动与音频。然后，FaceDecoder将修改和同步的潜码解码成视觉面部内容。

在第二阶段，Hyperlips利用从第一阶段生成的面部数据和相应的面部素描作为输入，通过一个高分辨率解码器（HRDecoder）来进一步优化生成的面部图像。这个过程通过面部素描的引导来实现面部的细节增强。

### 成果说明

在本项目中，HyperLips被重构并在talkingface-toolkit框架下实现了两个模型：HyperLipsBase和HyperLipsHR。这两个模型分别对应于HyperLips的两个阶段，以提供更高效和灵活的训练与评估过程。

#### 1）HyperLipsBase

**基础人脸生成（Base Face Generation）**:

- 这一阶段的目的是利用视觉和音频信息生成基础人脸图像。
- **FaceEncoder** 将视觉人脸信息（参考图像和遮罩图像）编码成潜在的代码。
- 通过HyperConv（一个卷积操作），修改潜在代码。HyperConv的权重参数由一个超网络（HyperNet）更新，该网络使用音频特征作为输入，从而实现了对渲染出的视觉人脸内容中的唇部运动的音频控制。
- **FaceDecoder** 解码修改后的潜在代码，生成可视的人脸内容，称为基础人脸（Base Face）。

实现了从MEAD数据集视频中抽取出人脸图像，audio.wav中提取声音信息，初步合成一段符合口型的视频文件。

#### 2）HyperLipsHR

**高保真渲染（High-Fidelity Rendering）**:

- 这是一个可选阶段，用于进一步提升生成人脸的保真度。
- 使用高分辨率解码器（HRDecoder）来优化生成的人脸的保真度。
- 网络使用第一阶段生成的面部数据和对应的面部草图进行训练，通过草图指导来实现面部增强。
- HRDecoder的输入是基础人脸与从基础人脸中提取的草图的连接特征，输出则是高保真的面部图像。



### 文件格式

```
HyperLips/
├─checkpoints                 //预训练模型
├─dataset                     //保存数据集
│  └─MEAD
│      ├─data                 //原始数据
│      ├─filelist             //数据集划分
│      └─preprocessed_data    //预处理完成后的数据集
│          ├─imgs	//HyperLipsBase训练用预处理过的数据
│          └─video_clips	//由原始数据生成的视频片段
│          └─HR_Train_Dateset	//HyperLipsHR训练用预处理过的数据
│          		└─GT_IMG
│          		└─GT_MASK
│          		└─GT_SKETCH
│          		└─HYPER_IMG
│          		└─HYPER_SKETCH
├─log
├─log_tensorboard
├─saved                       //保存处理完成后数据
└─talkingface                 
    ├─config                  //创建配置文件
    ├─data
    │  ├─dataprocess          //保存数据处理方法
    │  │  ├─hyperlipsbase_process.py          //HyperLipsBase数据预处理方法
    │  │  ├─hyperlipshr_process.py          //HyperLipsHR数据预处理方法
    │  ├─dataset              //保存数据集类
    │  │  ├─hyperlipsbase_dataset.py          //加载HyperLipsBase模型数据集
    │  │  ├─hyperlipshr_dataset.py          //加载HyperLipsBase模型数据集
    ├─evaluator               //评估函数
    ├─model
    │  ├─audio_driven_talkingface     //保存模型
    │  │  ├─hyperlipsbase.py          //保存HyperLipsBase模型
    │  │  ├─hyperlipshr.py            //保存HyperLipsHR模型
    │  ├─image_driven_talkingface
    │  ├─nerf_based_talkingface
    ├─properties              //配置文件
    │  ├─dataset              //保存数据集配置文件
    │  │  ├─MEAD.yaml     //数据集配置文件
    │  ├─model      
    │  │  ├─HyperLipsBase.yaml     //HyperlipsBase模型配置文件
    │  │  ├─HyperLipsHR.yaml       //HyperlipsHR模型配置文件
    │  └─overall.yaml              //全局配置文件
    ├─quick_start
    ├─trainer                 //保存训练模型类
    └─utils
        ├─HyperLips_utils     //保存模型加载的依赖函数
        ├─face_detection
```

在talkingface中，除了对于data、model、properties的添加与修改外，也在trainer中添加了与模型相关的额外的类，在utils中添加了HyperLips_utils这一与模型依赖相关的包。由于模型主要由两部分组成，因此将模型拆分为两个模型进行训练，分别使用不同路径下的处理数据。

## 2、运行过程

运行HyperLipsBase需保证MEAD.yaml文件中preprocessed_root的值为：'dataset/MEAD/preprocessed_data/imgs'；

运行HyperLipsHR需保证MEAD.yaml文件中preprocessed_root的值为：'dataset/MEAD/preprocessed_data'。

运行程序所需要的环境与原代码requirement.txt中要求的环境一致。原代码链接：[semchan/HyperLips: Pytorch official implementation for our paper "HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation". (github.com)](https://github.com/semchan/HyperLips)原论文链接：[[2310.05720\] HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation (arxiv.org)](https://arxiv.org/abs/2310.05720)

本次训练使用的数据集为MEAD，考虑到时间成本与设备问题对MEAD原始数据集进行了裁剪，只使用一个小的数据集运行。所使用的checkpoints和dataset百度网盘链接如下：https://pan.baidu.com/s/1wUEnGY-Q_MFcuCKVLZlhQg，提取码：a7b4

从链接获取到checkpoints和dataset后可直接将二者放在如上文件中的位置作为程序的checkpoints和dataset。

保证数据集按照上述文件格式放在了合适的位置，然后运行下列命令即可进行训练和评估。

```
# HyperLipsBase模型的训练和评估
python run_talkingface.py --model=HyperLipsBase --dataset=MEAD
```

```
# HyperLipsHR模型的训练和评估
python run_talkingface.py --model=HyperLipsHR --dataset=MEAD
```

HyperLipsBase训练及验证评估过程

![43424aabc342d542ce335f21015bee5](https://s2.loli.net/2024/01/27/ahrjGtSLXEmOUuB.png)

![c5460504e30d3cdc6380170c19a1fa4](https://s2.loli.net/2024/01/27/QfyqjEmGBPUkLA1.png)

HyperLipsHR训练及验证评估过程

![d5942df20bc229537712ebe7b5b474a](https://s2.loli.net/2024/01/27/IAHNih6S2qCybOZ.png)![d5942df20bc229537712ebe7b5b474a](https://s2.loli.net/2024/01/27/1LD76EsWXynNRmM.png)

![e3e202e71073275daae8d74cfbb4184](https://s2.loli.net/2024/01/27/jXUlKVObZyigGBJ.png)

## 3、环境依赖

```

audioread               3.0.1
basicsr                 1.4.2
colorlog                6.7.0
contourpy               1.1.1
decorator               5.1.1
facexlib                0.2.5
ffmpeg                  1.4
future                  0.18.3
google-auth             2.26.2
google-auth-oauthlib    1.0.0
imageio                 2.33.1
importlib-metadata      7.0.1
importlib-resources     6.1.1
librosa                 0.9.2
matplotlib              3.7.4
mediapipe               0.10.1
numba                   0.56.4
numpy                   1.21.5
oauthlib                3.2.2
opencv-contrib-python   4.7.0.72
opencv-python           4.7.0.72
packaging               23.2
pandas                  1.3.4
pillow                  10.2.0
python-speech-features  0.6
PyWavelets              1.4.1
PyYAML                  6.0.1
requests                2.31.0
setuptools              68.2.2
tensorboard-data-server 0.7.2
torch                   1.13.1+cu116
torchaudio              0.13.1+cu116
torchvision             0.14.1+cu116
tqdm                    4.65.0
```

GPU:RTX4070，显存12G

CPU：Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz   3.19 GHz

windows 10操作系统

## 4、成员分工

李中行：统筹分工与时间安排，分析HyperLips论文和源代码并添加注释，重构了hyperlipsbase和hyperlipshr两个模型的dataset部分以及dataprocess部分，将模型的各部分进行连接，规范整体框架格式，对模型进行主要的调试与修改工作，修改说明文档。

杨子钰：分析HyperLips论文和源代码并添加注释，负责hyperlipsbase和hyperlipshr模型部分的代码迁移、将模型的各部分进行连接与接口调试，编写两个模型的yaml文件，对模型进行主要的调试与修改工作，编写说明文档。

宋瑜航：分析HyperLips论文和源代码并添加注释，合作重构model下的hyperlipsbase.py和hyperlipshr.py，重写HyperLipsBase和HyperLipsHR的calculate_loss函数，参与模型调试工作，编写说明文档。

何浩天：分析HyperLips论文和源代码并添加注释，合作重构model下的hyperlipsbase.py和hyperlipshr.py，重写generate_batch函数，参与模型调试工作，编写说明文档。

徐立昂：分析HyperLips论文和源代码并添加注释，编写模型的yaml文件，对model文件下hyperlipsbase.py和hyperlipshr.py文件进行修改，参与模型调试工作，编写说明文档主要部分。




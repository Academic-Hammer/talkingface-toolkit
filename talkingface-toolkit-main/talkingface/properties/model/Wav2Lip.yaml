# Syncnet
syncnet_wt: 0.03 # (int) is initially zero, will be set automatically to 0.03 later.Leads to faster convergence.
syncnet_batch_size: 64 # (int) batch_size for syncnet train
syncnet_lr: 0.0001 #(float) learning rate for syncnet train
syncnet_eval_interval: 10000
syncnet_checkpoint_interval: 10000
syncnet_T: 5
syncnet_mel_step_size: 16
syncnet_checkpoint_path: "checkpoints/wav2lip/lipsync_expert.pth"

# Data preprocessing for Wav2lip
num_mels: 80
rescale: True
rescaling_max: 0.9
use_lws: False
n_fft: 800
hop_size: 200
win_size: 800
sample_rate: 16000
frame_shift_ms: None
signal_normalization: True
allow_clipping_in_normalization: True
symmetric_mels: True
max_abs_value: 4
preemphasize: True
preemphasis: 0.97
min_level_db: -100
ref_level_db: 20
fmin: 55
fmax: 7600
img_size: 96
fps: 25
mel_step_size: 16

batch_size: 16
ngpu: 1


# Train
checkpoint_sub_dir: "/wav2lip" # 和overall.yaml里checkpoint_dir拼起来作为最终目录

temp_sub_dir: "/wav2lip" # 和overall.yaml里temp_dir拼起来作为最终目录


# Inference
pads: [0, 10, 0, 0]
static: False
face_det_batch_size: 16
resize_factor: 1
crop: [0, -1, 0, -1]
box: [-1, -1, -1, -1]
rotate: False
nosmooth: False
wav2lip_batch_size: 128
vshift: 15